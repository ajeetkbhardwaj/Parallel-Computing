{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K57jtyzVyd25","executionInfo":{"status":"ok","timestamp":1755686326600,"user_tz":-330,"elapsed":5638,"user":{"displayName":"Ajeet Kumar","userId":"06013401403679424192"}},"outputId":"47800340-4373-4e9a-9dc3-bc533c71761c"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n","The nvcc4jupyter extension is already loaded. To reload it, use:\n","  %reload_ext nvcc4jupyter\n"]}],"source":["# check the Nvidia CUDA compiler driver install or not on T4 GPU of colab\n","!nvcc --version\n","# installing necessary package for running cuda kernel on the colab gpu in notebook\n","!pip install nvcc4jupyter --quiet\n","\n","# loading the package extension\n","%load_ext nvcc4jupyter"]},{"cell_type":"code","source":["%%cuda\n","// linear_regression_forward.cu\n","#include <iostream>\n","#include <cuda_runtime.h>\n","#include <chrono>\n","#include <cstdlib>\n","#include <ctime>\n","\n","// Forward pass on GPU\n","__global__ void linear_forward(float* X, float* w, float* b, float* y_pred, int num_samples, int num_features) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","    if (idx < num_samples) {\n","        float y = 0.0f;\n","        for (int j = 0; j < num_features; j++) {\n","            y += X[idx * num_features + j] * w[j];\n","        }\n","        y += *b;\n","        y_pred[idx] = y;\n","    }\n","}\n","\n","// Forward pass on CPU\n","void linear_forward_cpu(float* X, float* w, float b, float* y_pred, int num_samples, int num_features) {\n","    for (int i = 0; i < num_samples; i++) {\n","        float y = 0.0f;\n","        for (int j = 0; j < num_features; j++) {\n","            y += X[i * num_features + j] * w[j];\n","        }\n","        y += b;\n","        y_pred[i] = y;\n","    }\n","}\n","\n","int main() {\n","    const int num_samples = 1000;\n","    const int num_features = 10;\n","\n","    std::srand(std::time(0));\n","\n","    // Dynamically allocate large arrays\n","    float* h_X = new float[num_samples * num_features];\n","    float* h_w = new float[num_features];\n","    float* h_y_pred = new float[num_samples];\n","    float* h_y_true = new float[num_samples];\n","    float* h_y_cpu = new float[num_samples];\n","    float h_b = static_cast<float>(rand()) / RAND_MAX;\n","\n","    // Random initialization\n","    for (int i = 0; i < num_samples * num_features; ++i)\n","        h_X[i] = static_cast<float>(rand()) / RAND_MAX;\n","\n","    for (int i = 0; i < num_features; ++i)\n","        h_w[i] = static_cast<float>(rand()) / RAND_MAX;\n","\n","    // Generate true values (not groung truth labels)\n","    linear_forward_cpu(h_X, h_w, h_b, h_y_true, num_samples, num_features);\n","\n","    // GPU memory allocation\n","    float *d_X, *d_w, *d_b, *d_y_pred;\n","    cudaMalloc(&d_X, sizeof(float) * num_samples * num_features);\n","    cudaMalloc(&d_w, sizeof(float) * num_features);\n","    cudaMalloc(&d_b, sizeof(float));\n","    cudaMalloc(&d_y_pred, sizeof(float) * num_samples);\n","\n","    // CUDA timing\n","    cudaEvent_t start, stop;\n","    float time_memcpy_h2d, time_kernel, time_memcpy_d2h, total_gpu_time;\n","\n","    cudaEventCreate(&start);\n","    cudaEventCreate(&stop);\n","\n","    // Host to device\n","    cudaEventRecord(start);\n","    cudaMemcpy(d_X, h_X, sizeof(float) * num_samples * num_features, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_w, h_w, sizeof(float) * num_features, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_b, &h_b, sizeof(float), cudaMemcpyHostToDevice);\n","    cudaEventRecord(stop);\n","    cudaEventSynchronize(stop);\n","    cudaEventElapsedTime(&time_memcpy_h2d, start, stop);\n","\n","    // Launch kernel\n","    int blockSize = 1024;\n","    int gridSize = (num_samples + blockSize - 1) / blockSize;\n","\n","    cudaEventRecord(start);\n","    linear_forward<<<gridSize, blockSize>>>(d_X, d_w, d_b, d_y_pred, num_samples, num_features);\n","    cudaEventRecord(stop);\n","    cudaEventSynchronize(stop);\n","    cudaEventElapsedTime(&time_kernel, start, stop);\n","\n","    // Check for errors\n","    cudaError_t err = cudaGetLastError();\n","    if (err != cudaSuccess) {\n","        std::cerr << \"CUDA kernel error: \" << cudaGetErrorString(err) << std::endl;\n","        return -1;\n","    }\n","\n","    cudaDeviceSynchronize();\n","\n","    // Copy back result\n","    cudaEventRecord(start);\n","    cudaMemcpy(h_y_pred, d_y_pred, sizeof(float) * num_samples, cudaMemcpyDeviceToHost);\n","    cudaEventRecord(stop);\n","    cudaEventSynchronize(stop);\n","    cudaEventElapsedTime(&time_memcpy_d2h, start, stop);\n","\n","    total_gpu_time = time_memcpy_h2d + time_kernel + time_memcpy_d2h;\n","\n","    // CPU version\n","    auto cpu_start = std::chrono::high_resolution_clock::now();\n","    linear_forward_cpu(h_X, h_w, h_b, h_y_cpu, num_samples, num_features);\n","    auto cpu_end = std::chrono::high_resolution_clock::now();\n","    std::chrono::duration<double, std::milli> cpu_duration = cpu_end - cpu_start;\n","\n","    // Print first 10 results\n","    std::cout << \"\\nFirst 10 Predictions Comparison:\\n\";\n","    std::cout << \"Index\\tTrue y\\tGPU y\\tCPU y\\n\";\n","    for (int i = 0; i < 10; i++) {\n","        std::cout << i << \"\\t\"\n","                  << h_y_true[i] << \"\\t\"\n","                  << h_y_pred[i] << \"\\t\"\n","                  << h_y_cpu[i] << \"\\n\";\n","    }\n","\n","    // Timings\n","    std::cout << \"\\nGPU Timing (ms):\\n\";\n","    std::cout << \"Host to Device:       \" << time_memcpy_h2d << \" ms\\n\";\n","    std::cout << \"Kernel execution:     \" << time_kernel << \" ms\\n\";\n","    std::cout << \"Device to Host:       \" << time_memcpy_d2h << \" ms\\n\";\n","    std::cout << \"Total GPU time:       \" << total_gpu_time << \" ms\\n\";\n","\n","    std::cout << \"\\nTotal CPU time:       \" << cpu_duration.count() << \" ms\\n\";\n","\n","    // Cleanup\n","    cudaFree(d_X);\n","    cudaFree(d_w);\n","    cudaFree(d_b);\n","    cudaFree(d_y_pred);\n","    cudaEventDestroy(start);\n","    cudaEventDestroy(stop);\n","\n","    delete[] h_X;\n","    delete[] h_w;\n","    delete[] h_y_pred;\n","    delete[] h_y_true;\n","    delete[] h_y_cpu;\n","\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fea29U-x4NDW","executionInfo":{"status":"ok","timestamp":1755686334381,"user_tz":-330,"elapsed":4944,"user":{"displayName":"Ajeet Kumar","userId":"06013401403679424192"}},"outputId":"040c6934-ee42-4d99-9cb8-c9b533fcd254"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA kernel error: the provided PTX was compiled with an unsupported toolchain.\n","\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"IHslc9huy6VZ"}}]}